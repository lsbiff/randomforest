{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('benchmark.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('pima.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetColumn = 'target'\n",
    "modeValue = df[targetColumn].mode()[0]\n",
    "dfWithoutTarget = df.loc[:, df.columns != targetColumn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    return (data - min(data))/ (max(data) - min(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in dfWithoutTarget.columns:\n",
    "    df[feature] = normalize(df[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree:\n",
    "    \n",
    "    left = None\n",
    "    right = None\n",
    "    \n",
    "    def setAttribute(self, attribute):\n",
    "        self.attribute = attribute\n",
    "\n",
    "    def setValue(self, value):\n",
    "        self.value = value\n",
    "\n",
    "    def setLeft(self, left):\n",
    "        self.left = left\n",
    "\n",
    "    def setRight(self, right):\n",
    "        self.right = right\n",
    "        \n",
    "    def traverse(self, row):\n",
    "        if(self.left and self.right):\n",
    "            if(row[self.attribute] < self.value):\n",
    "                return self.left.traverse(row)\n",
    "            else:\n",
    "                return self.right.traverse(row)\n",
    "        else:\n",
    "            return self.value\n",
    "        \n",
    "    def __str__(self, depth=0):\n",
    "        \n",
    "        print('\\t' * (2*depth), end='')\n",
    "        print('['+self.attribute+']')\n",
    "        \n",
    "        if(self.left and self.right):\n",
    "            print('\\t' * ((2*depth)+1) + '<', end='')\n",
    "            print(self.value)\n",
    "            self.left.__str__(depth+1)\n",
    "            \n",
    "            print('\\t' * ((2*depth)+1) + '>=', end='')\n",
    "            print(self.value)\n",
    "            self.right.__str__(depth+1)\n",
    "        else:\n",
    "            print('\\t' * ((2*depth)+1), end='')\n",
    "            print('(', end='')\n",
    "            print(self.value, end='')\n",
    "            print(')')\n",
    "            \n",
    "        return 'Decision Tree'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    \n",
    "    def __init__(self, nTree, targetColumn, maxDepth):\n",
    "        self.nTree = nTree\n",
    "        self.targetColumn = targetColumn\n",
    "        self.maxDepth = maxDepth\n",
    "        \n",
    "    def columnsSubset(self, columnValues, m):\n",
    "        if m == len(columnValues):\n",
    "            return columnValues\n",
    "        columnsSubSet = np.random.choice(columnValues, m, replace=False)\n",
    "        return columnsSubSet\n",
    "    \n",
    "    def entropy(self, df, parentNodeSize):\n",
    "        if(len(df) == 0):\n",
    "            return 1.0\n",
    "        \n",
    "        classByAttribute = df.groupby(df[self.targetColumn]).size()\n",
    "\n",
    "        differentClasses = len(classByAttribute.index)\n",
    "        totalSum = classByAttribute.sum()\n",
    "        entropy = 0\n",
    "        for label in range(differentClasses):\n",
    "            labelSum = classByAttribute.iloc[label]\n",
    "            labelProbability = labelSum/totalSum\n",
    "            entropy -= labelProbability * (math.log(labelProbability,2))\n",
    "\n",
    "        try:\n",
    "            return entropy * (totalSum/ parentNodeSize)\n",
    "        except:\n",
    "            return 1.0\n",
    "    \n",
    "    def generatePartitions(self, df, attribute):\n",
    "        partitions = list()\n",
    "        df.sort_values(attribute, inplace=True)\n",
    "        bestSplitEntropy = 999\n",
    "        bestSplitValue = 0\n",
    "        for i in range(1,len(df)):\n",
    "            if(df[targetColumn].iloc[i] != df[targetColumn].iloc[i-1]):\n",
    "                splitValue = (df[attribute].iloc[i] + df[attribute].iloc[i-1])/2\n",
    "            \n",
    "                if(splitValue==0):\n",
    "                    splitValue += 0.00001\n",
    "                if(splitValue==1):\n",
    "                    splitValue -= 0.00001\n",
    "                    \n",
    "                leftData = df[df[attribute] < splitValue]\n",
    "                leftEntropy = self.entropy(leftData, len(leftData))\n",
    "                rightData = df[df[attribute] >= splitValue]\n",
    "                rightEntropy = self.entropy(rightData, len(rightData))\n",
    "                valueEntropy = leftEntropy + rightEntropy\n",
    "                if(valueEntropy < bestSplitEntropy):\n",
    "                    besSplitEntropy = valueEntropy\n",
    "                    bestSplitValue = splitValue\n",
    "        \n",
    "        partitions.append(df[df[attribute] < bestSplitValue])\n",
    "        partitions.append(df[df[attribute] >= bestSplitValue])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#         if(len(partitions[0])==0 or len(partitions[1])==0):\n",
    "#             import pdb; pdb.set_trace()\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        return (bestSplitValue, partitions)\n",
    "\n",
    "    def decisionTree(self, df, depth, treeNode):\n",
    "        classByAttribute = df.groupby(df[self.targetColumn]).size()\n",
    "        parentNodeSize = classByAttribute.sum()\n",
    "        parentNodeEntropy = self.entropy(df, parentNodeSize)\n",
    "        \n",
    "\n",
    "        if(parentNodeEntropy == 0 or depth == self.maxDepth):\n",
    "            leaf = Tree()\n",
    "            leaf.setAttribute(self.targetColumn)\n",
    "            if(len(df) > 0):\n",
    "                leaf.setValue(df[self.targetColumn].mode()[0])\n",
    "            else:\n",
    "                leaf.setValue(modeValue)\n",
    "            return leaf\n",
    "\n",
    "        mAttributes = round(math.sqrt(len(df.columns)))\n",
    "        attributes = df.loc[:, df.columns != self.targetColumn].columns\n",
    "        columnsSubSet = self.columnsSubset(attributes, mAttributes)\n",
    "        gainDict = {}\n",
    "        for attribute in columnsSubSet:\n",
    "            subsetEntropy = 0\n",
    "            partitions = self.generatePartitions(df, attribute)\n",
    "            for partition in partitions[1]:\n",
    "                    attributeEntropy = self.entropy(partition, parentNodeSize)\n",
    "                    subsetEntropy += attributeEntropy\n",
    "            gainDict[attribute] = parentNodeEntropy - subsetEntropy\n",
    "\n",
    "        highestGain = max(gainDict, key=lambda key: gainDict[key])\n",
    "\n",
    "        partitions = self.generatePartitions(df, highestGain)\n",
    "        \n",
    "        \n",
    "#         if(len(partitions[1][0])==0 or len(partitions[1][1])==0):\n",
    "#             import pdb; pdb.set_trace()\n",
    "            \n",
    "            \n",
    "            \n",
    "        newNode = Tree()\n",
    "        newNode.setAttribute(highestGain)\n",
    "        newNode.setValue(partitions[0])\n",
    "\n",
    "        #if it's the root\\n\"\n",
    "        if(depth == 0):\n",
    "            treeNode = newNode\n",
    "\n",
    "        left = self.decisionTree(partitions[1][0], depth+1, newNode)\n",
    "        newNode.setLeft(left)\n",
    "\n",
    "        right = self.decisionTree(partitions[1][1], depth+1, newNode)\n",
    "        newNode.setRight(right)\n",
    "\n",
    "        return newNode\n",
    "    \n",
    "    def createBootstraps(self, df):\n",
    "        bootstraps = list()\n",
    "        for i in range(self.nTree):\n",
    "            bootstraps.append(df.sample(frac=1, replace=True))\n",
    "\n",
    "        return bootstraps\n",
    "                     \n",
    "    def train(self, df):\n",
    "        randomForest = list()\n",
    "        bootstraps = self.createBootstraps(df)\n",
    "        for i in range(self.nTree):\n",
    "            print('Training Tree ', i)\n",
    "            tree = Tree()\n",
    "            trainData = bootstraps[i]\n",
    "            tree = self.decisionTree(trainData, 0, tree)\n",
    "            randomForest.append(tree)\n",
    "                     \n",
    "        self.randomForest = randomForest\n",
    "        \n",
    "    def predict(self, df):\n",
    "        predictedValues = list()\n",
    "        for index, row in df.iterrows():\n",
    "            votes = list()\n",
    "            for tree in self.randomForest:\n",
    "                vote = tree.traverse(row)\n",
    "                votes.append(vote)\n",
    "            \n",
    "            prediction = max(votes, key=votes.count)\n",
    "            predictedValues.append(prediction)\n",
    "            \n",
    "        return np.array(predictedValues)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFolds(df, k, targetColumn):\n",
    "    \n",
    "    targetClasses = df.groupby(df[targetColumn]).size().index.values\n",
    "    \n",
    "    partitionsByClass = list()\n",
    "    for targetClass in targetClasses:\n",
    "        classData = df[df[targetColumn]==targetClass]\n",
    "        classData = classData.sample(frac=1)\n",
    "        partitionsByClass.append(classData)\n",
    "        \n",
    "    proportions = list()\n",
    "    for i in range(len(targetClasses)):\n",
    "        step = (len(partitionsByClass[i])//k)\n",
    "        proportions.append((step, 0, step))\n",
    "    \n",
    "    folds = {}\n",
    "    for fold in range(k):\n",
    "        folds[fold] = pd.DataFrame()\n",
    "        for i in range(len(targetClasses)):\n",
    "            step = proportions[i][0]\n",
    "            posStart = proportions[i][1]\n",
    "            posEnd = proportions[i][2]\n",
    "            classData = partitionsByClass[i].iloc[posStart:posEnd, :]\n",
    "            folds[fold] = pd.concat([folds[fold], classData])\n",
    "            proportions[i] = (step, posEnd, posEnd + step)\n",
    "\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(actualValues, predictions):\n",
    "    return np.mean(actualValues == predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1score(actualValues, predictions):\n",
    "    truePositives = 0\n",
    "    falsePositives = 0\n",
    "    falseNegatives = 0\n",
    "    beta = 1\n",
    "\n",
    "    for i in range(len(actualValues)):\n",
    "        if (actualValues[i] == 1 and predictions[i] == 1):\n",
    "            truePositives += 1\n",
    "            \n",
    "        if (actualValues[i] == 1 and predictions[i] == 0):\n",
    "            falseNegatives += 1\n",
    "            \n",
    "        if (actualValues[i] == 0 and predictions[i] == 1):\n",
    "            falsePositives += 1\n",
    "    try:        \n",
    "        precision = truePositives / (truePositives + falsePositives)\n",
    "    except:\n",
    "        precision = np.NaN\n",
    "        \n",
    "    try:\n",
    "        recall = truePositives / (truePositives + falseNegatives)\n",
    "    except:\n",
    "        recall = np.NaN\n",
    "    \n",
    "    try:\n",
    "        f1score = (1 + (beta ** 2)) * ((precision * recall)/(((beta ** 2) * precision) + recall))\n",
    "    except:\n",
    "        f1score = np.NaN\n",
    "        \n",
    "        \n",
    "    return (precision, recall, f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold(model, df, k, targetColumn):\n",
    "    # shuffle and separate data\n",
    "    df = df.sample(frac=1)\n",
    "    \n",
    "    folds = generateFolds(df, k, targetColumn)\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1scores = []\n",
    "\n",
    "    for testIndex in range(k):\n",
    "        print('Fold ', testIndex)\n",
    "        test = folds[testIndex]\n",
    "        train = []\n",
    "        \n",
    "        for key in folds.keys():\n",
    "            if key != testIndex:\n",
    "                train.append(folds[key])\n",
    "        \n",
    "        train = pd.concat(train)\n",
    "        model.train(train)\n",
    "        \n",
    "        predictions = model.predict(test.loc[:, df.columns != targetColumn])\n",
    "        accuracies.append(accuracy(test[targetColumn], predictions))\n",
    "        metrics = f1score(test[targetColumn].values, predictions)\n",
    "        precisions. append(metrics[0])\n",
    "        recalls. append(metrics[1])\n",
    "        f1scores.append(metrics[2])\n",
    "    \n",
    "    accAvg = np.mean(accuracies)\n",
    "    accStd = np.std(accuracies)\n",
    "    precisionAvg = np.mean(precisions)\n",
    "    recallsAvg = np.mean(recalls)\n",
    "    f1Avg = np.mean([x for x in f1scores if not np.isnan(x)])\n",
    "    f1Std = np.std([x for x in f1scores if not np.isnan(x)])\n",
    "    print ('Accuracy Average:', accAvg)\n",
    "    print ('Accuracy Standard Deviation : ', accStd)\n",
    "    print ('Precision Average:', precisionAvg)\n",
    "    print ('Recall Average:', recallsAvg)\n",
    "    print ('F1Score Average: ', f1Avg)\n",
    "    print ('F1Score Standard Deviation : ', f1Std)\n",
    "        \n",
    "    return accAvg, accStd, f1Avg, f1Std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForest(5, targetColumn, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.nTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Tree  0\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Tree  1\n",
      "5\n",
      "Training Tree  2\n",
      "5\n",
      "Training Tree  3\n",
      "5\n",
      "Training Tree  4\n",
      "5\n",
      "Training Tree  5\n",
      "5\n",
      "Training Tree  6\n",
      "5\n",
      "Training Tree  7\n",
      "5\n",
      "Training Tree  8\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "train = kfold(model, df, 10, targetColumn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
